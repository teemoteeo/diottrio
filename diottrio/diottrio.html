<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>diottr.io — See What They See</title>
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=Instrument+Serif:ital@0;1&display=swap" rel="stylesheet">
	<!-- TensorFlow.js and Depth Estimation -->
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation@0.0.5/dist/depth-estimation.min.js"></script>
	<style>
		* {
			margin: 0;
			padding: 0;
			box-sizing: border-box;
		}

		:root {
			--bg-dark: #0a0a0a;
			--text-primary: #f0f0f0;
			--text-muted: #6a6a6a;
			--accent: #ff3b30;
			--accent-glow: rgba(255, 59, 48, 0.3);
		}

		body {
			font-family: 'Space Mono', monospace;
			background: var(--bg-dark);
			color: var(--text-primary);
			min-height: 100vh;
			overflow-x: hidden;
		}

		.noise {
			position: fixed;
			top: 0;
			left: 0;
			width: 100%;
			height: 100%;
			pointer-events: none;
			opacity: 0.03;
			z-index: 1000;
			background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 200 200' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noiseFilter'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noiseFilter)'/%3E%3C/svg%3E");
		}

		header {
			padding: 2rem 3rem;
			display: flex;
			justify-content: space-between;
			align-items: center;
			border-bottom: 1px solid rgba(255,255,255,0.06);
		}

		.logo {
			font-family: 'Instrument Serif', serif;
			font-size: 2rem;
			letter-spacing: -0.02em;
		}

		.logo span {
			color: var(--accent);
		}

		.tagline {
			font-size: 0.7rem;
			text-transform: uppercase;
			letter-spacing: 0.3em;
			color: var(--text-muted);
		}

		main {
			padding: 2rem 3rem;
		}

		.diopter-control {
			margin-bottom: 2rem;
			padding: 2rem;
			background: rgba(255,255,255,0.02);
			border: 1px solid rgba(255,255,255,0.06);
			border-radius: 2px;
		}

		.eye-controls {
			display: grid;
			grid-template-columns: 1fr 1fr;
			gap: 2rem;
			margin-bottom: 1.5rem;
		}

		.dominance-control {
			display: flex;
			justify-content: center;
			align-items: center;
			gap: 1rem;
			padding: 1rem 0;
			border-top: 1px solid rgba(255,255,255,0.06);
			margin-top: 1rem;
		}

		.dominance-label {
			font-size: 0.65rem;
			text-transform: uppercase;
			letter-spacing: 0.2em;
			color: var(--text-muted);
		}

		.dominance-toggle {
			display: flex;
			gap: 0.5rem;
		}

		.dominance-btn {
			padding: 0.5rem 1rem;
			background: rgba(255,255,255,0.02);
			border: 1px solid rgba(255,255,255,0.1);
			color: var(--text-muted);
			font-family: 'Space Mono', monospace;
			font-size: 0.65rem;
			text-transform: uppercase;
			letter-spacing: 0.1em;
			cursor: pointer;
			transition: all 0.2s ease;
		}

		.dominance-btn:hover {
			background: rgba(255,255,255,0.05);
			border-color: rgba(255,255,255,0.2);
		}

		.dominance-btn.active {
			background: var(--accent);
			border-color: var(--accent);
			color: var(--bg-dark);
			box-shadow: 0 0 20px var(--accent-glow);
		}

		.eye-control {
			padding: 1.5rem;
			background: rgba(255,255,255,0.01);
			border: 1px solid rgba(255,255,255,0.04);
		}

		.diopter-label {
			display: flex;
			justify-content: space-between;
			align-items: baseline;
			margin-bottom: 1.5rem;
		}

		.diopter-title {
			font-size: 0.7rem;
			text-transform: uppercase;
			letter-spacing: 0.2em;
			color: var(--text-muted);
		}

		.diopter-value {
			font-family: 'Instrument Serif', serif;
			font-size: 2.5rem;
			color: var(--accent);
			text-shadow: 0 0 40px var(--accent-glow);
		}

		.diopter-value::after {
			content: ' D';
			font-size: 1.2rem;
			color: var(--text-muted);
		}

		.slider-container {
			position: relative;
		}

		.slider-track {
			display: flex;
			justify-content: space-between;
			margin-bottom: 0.5rem;
			font-size: 0.6rem;
			color: var(--text-muted);
		}

		input[type="range"] {
			width: 100%;
			height: 2px;
			background: rgba(255,255,255,0.1);
			outline: none;
			-webkit-appearance: none;
			appearance: none;
		}

		input[type="range"]::-webkit-slider-thumb {
			-webkit-appearance: none;
			width: 20px;
			height: 20px;
			background: var(--accent);
			border-radius: 50%;
			cursor: grab;
			box-shadow: 0 0 20px var(--accent-glow);
			transition: transform 0.15s ease;
		}

		input[type="range"]::-webkit-slider-thumb:hover {
			transform: scale(1.2);
		}

		input[type="range"]::-moz-range-thumb {
			width: 20px;
			height: 20px;
			background: var(--accent);
			border-radius: 50%;
			cursor: grab;
			border: none;
			box-shadow: 0 0 20px var(--accent-glow);
		}

		.vision-comparison {
			display: grid;
			grid-template-columns: 1fr 1fr;
			gap: 1rem;
		}

		.vision-panel {
			position: relative;
			aspect-ratio: 16/9;
			background: #111;
			overflow: hidden;
			border: 1px solid rgba(255,255,255,0.06);
		}

		.panel-label {
			position: absolute;
			top: 1rem;
			left: 1rem;
			font-size: 0.6rem;
			text-transform: uppercase;
			letter-spacing: 0.2em;
			color: var(--text-muted);
			z-index: 10;
			background: rgba(0,0,0,0.7);
			padding: 0.5rem 0.75rem;
			backdrop-filter: blur(10px);
		}

		.vision-panel video,
		.vision-panel img {
			width: 100%;
			height: 100%;
			object-fit: cover;
		}

		.vision-panel.blurred video,
		.vision-panel.blurred img {
			display: none;
		}

		.vision-panel.blurred canvas {
			width: 100%;
			height: 100%;
			object-fit: cover;
		}

		.resolution-badge {
			position: absolute;
			bottom: 1rem;
			right: 1rem;
			font-size: 0.55rem;
			text-transform: uppercase;
			letter-spacing: 0.15em;
			color: var(--accent);
			background: rgba(0,0,0,0.8);
			padding: 0.4rem 0.6rem;
			border: 1px solid rgba(255,59,48,0.3);
			z-index: 10;
		}

		.info-bar {
			margin-top: 2rem;
			padding: 1.5rem 2rem;
			background: rgba(255,59,48,0.05);
			border-left: 2px solid var(--accent);
			font-size: 0.75rem;
			line-height: 1.8;
			color: var(--text-muted);
		}

		.info-bar strong {
			color: var(--text-primary);
		}

		.source-indicator {
			position: absolute;
			top: 1rem;
			right: 1rem;
			font-size: 0.55rem;
			text-transform: uppercase;
			letter-spacing: 0.1em;
			padding: 0.4rem 0.6rem;
			background: rgba(0,0,0,0.8);
			border: 1px solid rgba(255,255,255,0.1);
			z-index: 10;
		}

		.source-indicator.camera {
			color: #34c759;
			border-color: rgba(52,199,89,0.3);
		}

		.source-indicator.fallback {
			color: var(--accent);
			border-color: rgba(255,59,48,0.3);
		}

		footer {
			padding: 2rem 3rem;
			border-top: 1px solid rgba(255,255,255,0.06);
			display: flex;
			justify-content: space-between;
			align-items: center;
			font-size: 0.65rem;
			color: var(--text-muted);
			text-transform: uppercase;
			letter-spacing: 0.15em;
		}

		.fps-counter {
			color: #34c759;
			font-weight: 700;
		}

		.fps-counter.low {
			color: var(--accent);
		}

		@media (max-width: 1200px) {
			.vision-comparison {
				grid-template-columns: 1fr;
			}

			.eye-controls {
				grid-template-columns: 1fr;
				gap: 1rem;
			}

			header {
				flex-direction: column;
				gap: 0.5rem;
				text-align: center;
			}

			main {
				padding: 1.5rem;
			}
		}

		.loading-state {
			display: flex;
			align-items: center;
			justify-content: center;
			height: 100%;
			color: var(--text-muted);
			font-size: 0.7rem;
			text-transform: uppercase;
			letter-spacing: 0.2em;
		}

		.loading-state::after {
			content: '';
			width: 6px;
			height: 6px;
			background: var(--accent);
			border-radius: 50%;
			margin-left: 0.75rem;
			animation: pulse 1s infinite;
		}

		@keyframes pulse {
			0%, 100% { opacity: 0.3; }
			50% { opacity: 1; }
		}
	</style>
</head>
<body>
	<div class="noise"></div>

	<header>
		<div class="logo">diottr<span>.</span>io</div>
		<div class="tagline">Experience impaired vision</div>
	</header>

	<main>
		<div class="diopter-control">
			<div class="eye-controls">
				<div class="eye-control">
					<div class="diopter-label">
						<span class="diopter-title">Left Eye (OS)</span>
						<span class="diopter-value" id="diopter-left-display">0.0</span>
					</div>
					<div class="slider-container">
						<div class="slider-track">
							<span>0</span>
							<span>-2</span>
							<span>-4</span>
							<span>-6</span>
							<span>-8</span>
							<span>-10</span>
						</div>
						<input type="range" id="diopter-left-slider" min="0" max="10" step="0.25" value="0" aria-label="Left eye diopter adjustment">
					</div>
				</div>
				<div class="eye-control">
					<div class="diopter-label">
						<span class="diopter-title">Right Eye (OD)</span>
						<span class="diopter-value" id="diopter-right-display">0.0</span>
					</div>
					<div class="slider-container">
						<div class="slider-track">
							<span>0</span>
							<span>-2</span>
							<span>-4</span>
							<span>-6</span>
							<span>-8</span>
							<span>-10</span>
						</div>
						<input type="range" id="diopter-right-slider" min="0" max="10" step="0.25" value="0" aria-label="Right eye diopter adjustment">
					</div>
				</div>
			</div>
			<div class="dominance-control">
				<span class="dominance-label">Dominant Eye:</span>
				<div class="dominance-toggle">
					<button class="dominance-btn active" id="dominant-left">Left</button>
					<button class="dominance-btn" id="dominant-right">Right</button>
				</div>
			</div>
		</div>

		<div class="vision-comparison">
			<div class="vision-panel" id="panel-clear">
				<div class="loading-state">Initializing</div>
				<span class="panel-label">Normal Vision (20/20)</span>
				<span class="resolution-badge">1080p</span>
			</div>
			<div class="vision-panel blurred" id="panel-combined">
				<div class="loading-state">Initializing</div>
				<span class="panel-label">Binocular Vision</span>
				<span class="resolution-badge">1080p + blur</span>
			</div>
		</div>

		<div class="info-bar">
			<strong>How it works:</strong> This simulation uses a <strong>dominant eye bias model</strong> where your brain combines inputs from both eyes, giving ~65% weight to your dominant eye and ~35% to the non-dominant eye.
			Each diopter represents approximately <strong>0.25-0.33 meters</strong> of clear vision distance. At -3D, objects beyond ~33cm become blurry.
			At -10D, clear vision ends at just 10cm from your eyes.
		</div>
	</main>

	<footer>
		<span>Simulation only — not medical advice</span>
		<span id="source-status">Detecting camera...</span>
		<span class="fps-counter" id="fps-counter">FPS: --</span>
	</footer>

	<script>
		// Configuration
		const FALLBACK_VIDEO_URL = './14903546_3840_2160_25fps.mp4';
		const DOMINANT_WEIGHT = 0.65;
		const BLUR_BASE = 1.4;
		const BLUR_EXPONENT = 1.1;

		// Depth-aware blur configuration
		const DEPTH_SLICES = 5;
		const DEPTH_FRAME_SKIP = 3; // Process depth every N frames
		const NEAR_THRESHOLD = 0.3;
		const DEPTH_BLUR_BASE = 8.0;

		// DOM references
		const panelClear = document.getElementById('panel-clear');
		const panelCombined = document.getElementById('panel-combined');
		const diopterLeftSlider = document.getElementById('diopter-left-slider');
		const diopterRightSlider = document.getElementById('diopter-right-slider');
		const diopterLeftDisplay = document.getElementById('diopter-left-display');
		const diopterRightDisplay = document.getElementById('diopter-right-display');
		const dominantLeftBtn = document.getElementById('dominant-left');
		const dominantRightBtn = document.getElementById('dominant-right');
		const sourceStatus = document.getElementById('source-status');
		const fpsCounter = document.getElementById('fps-counter');

		let mediaStream = null;
		let leftDiopters = 0;
		let rightDiopters = 0;
		let isDominantLeft = true;
		let animationFrameId = null;

		// Depth estimation state
		let depthEstimator = null;
		let depthMap = null;
		let frameCount = 0;
		let useDepthEstimation = false;
		let lastDepthUpdate = 0;

		// Cached canvas resources (prevent memory leaks)
		let cachedMaskCanvases = [];
		let cachedMaskContexts = [];
		let cachedTempCanvas = null;
		let cachedTempContext = null;
		let cachedMainContext = null;
		let cachedCanvasWidth = 0;
		let cachedCanvasHeight = 0;

		// FPS tracking
		let fpsFrameCount = 0;
		let fpsLastTime = performance.now();
		let currentFPS = 0;

		function calculateBlur(diopters) {
			return diopters === 0 ? 0 : BLUR_BASE * Math.pow(diopters, BLUR_EXPONENT);
		}

		function calculateBinocularBlur() {
			const dominantDiopters = isDominantLeft ? leftDiopters : rightDiopters;
			const nonDominantDiopters = isDominantLeft ? rightDiopters : leftDiopters;
			const weightedDiopters = dominantDiopters * DOMINANT_WEIGHT + nonDominantDiopters * (1 - DOMINANT_WEIGHT);
			return calculateBlur(weightedDiopters);
		}

		function updateBinocularVision() {
			// The render loop will pick up the new blur values automatically
		}

		// Initialize depth estimation model
		async function initDepthModel() {
			try {
				if (!window.depthEstimation) {
					console.log('Depth estimation library not loaded, using fallback');
					return;
				}

				console.log('Initializing depth estimation model...');
				const model = depthEstimation.SupportedModels.ARPortraitDepth;
				const estimatorConfig = {
					outputDepthRange: [0, 1]
				};

				depthEstimator = await depthEstimation.createEstimator(model, estimatorConfig);
				useDepthEstimation = true;
				console.log('Depth estimation model initialized successfully');
			} catch (error) {
				console.log('Failed to initialize depth model, using uniform blur:', error.message);
				useDepthEstimation = false;
			}
		}

		// Extract depth map from video
		async function getDepthMap(video) {
			if (!depthEstimator || !useDepthEstimation) {
				return null;
			}

			try {
				const depthData = await depthEstimator.estimateDepth(video);
				if (!depthData || !depthData.toCanvasImageSource) {
					return null;
				}

				// Get the depth tensor and convert to normalized values
				const depthTensor = depthData.toTensor();
				const data = await depthTensor.data();
				depthTensor.dispose();

				return data;
			} catch (error) {
				console.log('Depth estimation failed:', error.message);
				return null;
			}
		}

		// Create depth mask for a specific depth slice (uses cached canvases)
		function createDepthMask(depthData, width, height, minDepth, maxDepth, sliceIndex) {
			const maskCanvas = cachedMaskCanvases[sliceIndex];
			const maskCtx = cachedMaskContexts[sliceIndex];
			const imageData = maskCtx.createImageData(width, height);

			// Use Uint32Array for faster pixel operations (write all 4 channels at once)
			const data32 = new Uint32Array(imageData.data.buffer);
			const white = 0xFFFFFFFF; // ABGR: opaque white
			const transparent = 0x00000000;

			for (let i = 0; i < depthData.length; i++) {
				const depth = depthData[i];
				// Write all 4 channels at once using Uint32Array
				data32[i] = (depth >= minDepth && depth < maxDepth) ? white : transparent;
			}

			maskCtx.putImageData(imageData, 0, 0);
			return maskCanvas;
		}

		// Calculate blur amount based on depth and diopters
		function calculateDepthBlur(depth, diopters) {
			if (diopters === 0 || depth < NEAR_THRESHOLD) {
				return 0; // Sharp for near objects or no myopia
			}

			// Focal distance in meters (1 / diopters)
			const focalDist = 1 / diopters;

			// Estimate object distance from depth (assuming depth of 1 = 5 meters)
			const objectDist = depth * 5.0;

			// Blur formula: blurPx = (objectDist - focalDist) / focalDist * BLUR_BASE * diopters^0.8
			if (objectDist <= focalDist) {
				return 0; // Object is within focal distance, sharp
			}

			const relativeDistance = (objectDist - focalDist) / focalDist;
			const blurAmount = relativeDistance * DEPTH_BLUR_BASE * Math.pow(diopters, 0.8);

			return Math.max(0, Math.min(blurAmount, 50)); // Clamp between 0 and 50px
		}

		// Initialize cached canvases (called once or when size changes)
		function initializeCachedCanvases(width, height) {
			// Check if we need to resize
			if (cachedCanvasWidth === width && cachedCanvasHeight === height && cachedMaskCanvases.length > 0) {
				return; // Already initialized with correct size
			}

			cachedCanvasWidth = width;
			cachedCanvasHeight = height;

			// Create mask canvases for each depth slice
			cachedMaskCanvases = [];
			cachedMaskContexts = [];
			for (let i = 0; i < DEPTH_SLICES; i++) {
				const canvas = document.createElement('canvas');
				canvas.width = width;
				canvas.height = height;
				cachedMaskCanvases.push(canvas);
				cachedMaskContexts.push(canvas.getContext('2d', { willReadFrequently: false }));
			}

			// Create temp canvas for blurred video
			cachedTempCanvas = document.createElement('canvas');
			cachedTempCanvas.width = width;
			cachedTempCanvas.height = height;
			cachedTempContext = cachedTempCanvas.getContext('2d', { willReadFrequently: false });
		}

		// Apply depth-aware blur using layered rendering (uses cached canvases)
		function applyDepthAwareBlur(video, canvas, depthData, diopters) {
			if (!cachedMainContext) {
				cachedMainContext = canvas.getContext('2d', { willReadFrequently: false });
			}

			if (!cachedMainContext || !depthData) {
				// Fallback to uniform blur
				applySimpleBlur(video, canvas, calculateBlur(diopters));
				return;
			}

			const width = canvas.width;
			const height = canvas.height;

			// Initialize or resize cached canvases if needed
			initializeCachedCanvases(width, height);

			// Clear canvas
			cachedMainContext.clearRect(0, 0, width, height);

			// Render in depth slices (5 layers)
			for (let i = 0; i < DEPTH_SLICES; i++) {
				const minDepth = i / DEPTH_SLICES;
				const maxDepth = (i + 1) / DEPTH_SLICES;
				const avgDepth = (minDepth + maxDepth) / 2;

				// Calculate blur for this depth slice
				const blurPx = calculateDepthBlur(avgDepth, diopters);

				// Draw video with blur to temp canvas
				cachedTempContext.clearRect(0, 0, width, height);
				cachedTempContext.filter = `blur(${blurPx}px)`;
				cachedTempContext.drawImage(video, 0, 0, width, height);
				cachedTempContext.filter = 'none';

				// Create depth mask for this slice
				const mask = createDepthMask(depthData, width, height, minDepth, maxDepth, i);

				// Composite masked layer onto main canvas
				cachedMainContext.save();
				cachedMainContext.globalCompositeOperation = 'source-over';

				// Use mask to only draw pixels in this depth range
				cachedMainContext.drawImage(mask, 0, 0);
				cachedMainContext.globalCompositeOperation = 'source-in';
				cachedMainContext.drawImage(cachedTempCanvas, 0, 0);
				cachedMainContext.globalCompositeOperation = 'source-over';
				cachedMainContext.restore();
			}
		}

		function updateEyeDisplay(display, diopters) {
			display.textContent = diopters > 0 ? `-${diopters.toFixed(2)}` : '0.00';
		}

		// Update FPS counter
		function updateFPS() {
			fpsFrameCount++;
			const now = performance.now();
			const elapsed = now - fpsLastTime;

			if (elapsed >= 1000) {
				currentFPS = Math.round((fpsFrameCount * 1000) / elapsed);
				fpsFrameCount = 0;
				fpsLastTime = now;

				if (fpsCounter) {
					fpsCounter.textContent = `FPS: ${currentFPS}`;
					fpsCounter.classList.toggle('low', currentFPS < 30);
				}
			}
		}

		function createVideoElement(src, isStream) {
			const video = document.createElement('video');
			Object.assign(video, { autoplay: true, playsInline: true, muted: true, loop: true });
			if (isStream) {
				video.srcObject = src;
			// Explicitly play the stream (don't rely on autoplay on Mac)
			video.play().catch(e => console.log('Stream play error:', e));
			} else {
				video.src = src;
				video.play().catch(e => console.log('Video play error:', e));
			}
			return video;
		}

		function makeHiddenVideo(video) {
			Object.assign(video.style, { position: 'absolute', opacity: '0', pointerEvents: 'none' });
		}

		function applySimpleBlur(video, canvas, blurAmount) {
			const ctx = canvas.getContext('2d');
			if (!ctx) {
				console.error('Failed to get canvas context');
				return;
			}

			// Debug: log first few frames
			if (!window.frameCount) window.frameCount = 0;
			if (window.frameCount < 5) {
				console.log('Frame', window.frameCount, '- video ready:', video.readyState, 'blur:', blurAmount, 'canvas:', canvas.width, 'x', canvas.height);
				window.frameCount++;
			}

			ctx.filter = `blur(${blurAmount}px)`;
			ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
			ctx.filter = 'none';
		}

		function setupPanel(panel, content, isCamera, keepHiddenVideo = false) {
			// Remove loading state
			const loading = panel.querySelector('.loading-state');
			if (loading) loading.remove();

			// Replace existing content but keep hidden video if requested
			const existingCanvas = panel.querySelector('canvas');
			if (existingCanvas) existingCanvas.remove();

			if (!keepHiddenVideo) {
				const existingVideo = panel.querySelector('video');
				if (existingVideo) {
					existingVideo.pause();
					existingVideo.srcObject = null;
					existingVideo.src = '';
					existingVideo.remove();
				}
			}

			panel.insertBefore(content, panel.firstChild);

			// Update or create source indicator
			let sourceIndicator = panel.querySelector('.source-indicator');
			if (!sourceIndicator) {
				sourceIndicator = document.createElement('span');
				sourceIndicator.className = 'source-indicator';
				panel.appendChild(sourceIndicator);
			}
			sourceIndicator.className = `source-indicator ${isCamera ? 'camera' : 'fallback'}`;
			sourceIndicator.textContent = isCamera ? '● Live' : '● Video';
		}

		function startBlurRender(video, canvas) {
			console.log('startBlurRender called with video:', video, 'canvas:', canvas);
			let renderCount = 0;

			async function render() {
				if (renderCount < 3) {
					console.log('Render loop', renderCount, '- readyState:', video.readyState, 'HAVE_CURRENT_DATA:', video.HAVE_CURRENT_DATA);
					renderCount++;
				}

				if (video.readyState >= video.HAVE_CURRENT_DATA) {
					frameCount++;

					// Update depth map every DEPTH_FRAME_SKIP frames
					if (useDepthEstimation && frameCount % DEPTH_FRAME_SKIP === 0) {
						const newDepthMap = await getDepthMap(video);
						if (newDepthMap) {
							depthMap = newDepthMap;
							lastDepthUpdate = frameCount;
						}
					}

					// Get binocular diopters
					const dominantDiopters = isDominantLeft ? leftDiopters : rightDiopters;
					const nonDominantDiopters = isDominantLeft ? rightDiopters : leftDiopters;
					const weightedDiopters = dominantDiopters * DOMINANT_WEIGHT + nonDominantDiopters * (1 - DOMINANT_WEIGHT);

					// Apply depth-aware blur if available, otherwise fallback to uniform blur
					if (useDepthEstimation && depthMap && (frameCount - lastDepthUpdate) < 30) {
						applyDepthAwareBlur(video, canvas, depthMap, weightedDiopters);
					} else {
						const blurPx = calculateBlur(weightedDiopters);
						applySimpleBlur(video, canvas, blurPx);
					}

					// Update FPS counter
					updateFPS();
				} else if (renderCount < 3) {
					console.log('Video not ready yet, skipping frame');
				}

				animationFrameId = requestAnimationFrame(render);
			}
			render();
		}

		async function initCamera() {
			try {
				mediaStream = await navigator.mediaDevices.getUserMedia({
					video: { width: { ideal: 1920 }, height: { ideal: 1080 } }
				});

				const video1 = createVideoElement(mediaStream, true);

				setupPanel(panelClear, video1, true);

				// Wait for video to have valid dimensions before creating canvas
				let canvasSetupDone = false;
				const setupCanvas = () => {
					if (canvasSetupDone) return; // Only run once

					console.log('setupCanvas called, readyState:', video1.readyState, 'dimensions:', video1.videoWidth, 'x', video1.videoHeight);

					if (video1.videoWidth > 0 && video1.videoHeight > 0) {
						canvasSetupDone = true;
						const canvas = document.createElement('canvas');
						canvas.width = video1.videoWidth;
						canvas.height = video1.videoHeight;
						canvas.style.display = 'block'; // Ensure canvas is visible
						console.log('Canvas created with dimensions:', canvas.width, 'x', canvas.height);
						setupPanel(panelCombined, canvas, true, false);
						console.log('Canvas appended to DOM');
						// Test: try drawing one frame immediately
						setTimeout(() => {
							console.log('Test draw - video readyState:', video1.readyState, 'paused:', video1.paused);
							const ctx = canvas.getContext('2d');
							ctx.fillStyle = 'red';
							ctx.fillRect(0, 0, 100, 100); // Draw red square as test
							console.log('Red square drawn');
							setTimeout(() => {
								try {
									ctx.drawImage(video1, 0, 0, canvas.width, canvas.height);
									console.log('Successfully drew video frame to canvas');
								} catch (e) {
									console.error('Failed to draw video:', e);
								}
							}, 500);
						}, 100);

						startBlurRender(video1, canvas);
						console.log('Blur rendering started');
					} else {
						// Retry if dimensions not ready yet
						console.log('Retrying... dimensions not ready');
						requestAnimationFrame(setupCanvas);
					}
				};

				video1.addEventListener('loadedmetadata', setupCanvas);
				video1.addEventListener('loadeddata', setupCanvas);
				video1.addEventListener('playing', setupCanvas);

				sourceStatus.textContent = 'Source: Device Camera';
			} catch (err) {
				console.log('Camera not available, using fallback video:', err.message);
				useFallbackVideo();
			}
		}

		function handleVideoError(panel, panelName) {
			panel.innerHTML = `<div class="loading-state">Video failed to load</div>`;
			console.error(`${panelName} video failed to load`);
		}

		function useFallbackVideo() {
			const video1 = createVideoElement(FALLBACK_VIDEO_URL, false);
			const video2 = createVideoElement(FALLBACK_VIDEO_URL, false);

			video1.onloadeddata = () => setupPanel(panelClear, video1, false);
			video1.onerror = () => handleVideoError(panelClear, 'Clear');

			makeHiddenVideo(video2);
			panelCombined.appendChild(video2);

			video2.onloadeddata = () => {
				const canvas = document.createElement('canvas');
				canvas.width = video2.videoWidth;
				canvas.height = video2.videoHeight;
				setupPanel(panelCombined, canvas, false, true);
				startBlurRender(video2, canvas);
			};
			video2.onerror = () => handleVideoError(panelCombined, 'Combined');

			sourceStatus.textContent = 'Source: Sample Video';
		}

		function setDominantEye(isLeft) {
			isDominantLeft = isLeft;
			dominantLeftBtn.classList.toggle('active', isLeft);
			dominantRightBtn.classList.toggle('active', !isLeft);
			updateBinocularVision();
		}

		async function init() {
			updateEyeDisplay(diopterLeftDisplay, 0);
			updateEyeDisplay(diopterRightDisplay, 0);

			diopterLeftSlider.addEventListener('input', (e) => {
				leftDiopters = parseFloat(e.target.value);
				updateEyeDisplay(diopterLeftDisplay, leftDiopters);
			});

			diopterRightSlider.addEventListener('input', (e) => {
				rightDiopters = parseFloat(e.target.value);
				updateEyeDisplay(diopterRightDisplay, rightDiopters);
			});

			dominantLeftBtn.addEventListener('click', () => setDominantEye(true));
			dominantRightBtn.addEventListener('click', () => setDominantEye(false));

			// Initialize depth estimation model
			await initDepthModel();

			navigator.mediaDevices?.getUserMedia ? initCamera() : useFallbackVideo();
		}

		// Cleanup on page unload
		window.addEventListener('beforeunload', () => {
			if (animationFrameId) {
				cancelAnimationFrame(animationFrameId);
			}
			if (mediaStream) {
				mediaStream.getTracks().forEach(track => track.stop());
			}
			// Dispose TensorFlow.js resources
			if (depthEstimator && depthEstimator.dispose) {
				depthEstimator.dispose();
			}
		});

		// Initialize when DOM is ready
		if (document.readyState === 'loading') {
			document.addEventListener('DOMContentLoaded', init);
		} else {
			init();
		}
	</script>
</body>
</html>