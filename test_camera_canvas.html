<!DOCTYPE html>
<html>
<head>
	<title>Simple Camera to Canvas Test</title>
	<style>
		body {
			background: #000;
			color: #fff;
			font-family: monospace;
			padding: 20px;
		}
		.container {
			display: grid;
			grid-template-columns: 1fr 1fr;
			gap: 20px;
			margin: 20px 0;
		}
		video, canvas {
			width: 100%;
			border: 2px solid #fff;
		}
		#log {
			background: #111;
			padding: 10px;
			height: 200px;
			overflow-y: auto;
			font-size: 12px;
			margin-top: 20px;
			border: 1px solid #333;
		}
		.log-entry {
			padding: 2px 0;
		}
		.error {
			color: #f00;
		}
		.success {
			color: #0f0;
		}
	</style>
</head>
<body>
	<h1>Camera to Canvas Test - Mac Debugging</h1>
	<p>This is a minimal test to isolate the canvas rendering issue.</p>

	<div class="container">
		<div>
			<h3>Video Element</h3>
			<video id="video" autoplay playsinline muted></video>
		</div>
		<div>
			<h3>Canvas Element</h3>
			<canvas id="canvas"></canvas>
		</div>
	</div>

	<div id="log"></div>

	<script>
		const log = document.getElementById('log');

		function addLog(message, isError = false, isSuccess = false) {
			const entry = document.createElement('div');
			entry.className = 'log-entry' + (isError ? ' error' : '') + (isSuccess ? ' success' : '');
			entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
			log.appendChild(entry);
			log.scrollTop = log.scrollHeight;
			console.log(message);
		}

		async function init() {
			try {
				addLog('Requesting camera access...');

				const stream = await navigator.mediaDevices.getUserMedia({
					video: { width: { ideal: 1920 }, height: { ideal: 1080 } }
				});

				addLog('Camera access granted', false, true);

				const video = document.getElementById('video');
				const canvas = document.getElementById('canvas');

				video.srcObject = stream;
				addLog('Stream assigned to video element');

				// Explicitly play
				await video.play();
				addLog('Video play() called', false, true);

				// Wait for metadata
				video.addEventListener('loadedmetadata', () => {
					addLog(`Video metadata loaded - dimensions: ${video.videoWidth} x ${video.videoHeight}`);

					if (video.videoWidth > 0 && video.videoHeight > 0) {
						canvas.width = video.videoWidth;
						canvas.height = video.videoHeight;
						addLog(`Canvas sized to: ${canvas.width} x ${canvas.height}`, false, true);
					}
				});

				// Wait for video to actually be playing
				video.addEventListener('playing', () => {
					addLog('Video is now playing', false, true);

					// Try to render to canvas
					setTimeout(() => {
						addLog('Attempting to draw to canvas...');

						const ctx = canvas.getContext('2d');

						// Test 1: Draw a colored rectangle
						ctx.fillStyle = 'red';
						ctx.fillRect(0, 0, 100, 100);
						addLog('Red square test drawn', false, true);

						// Test 2: Try to draw video
						setTimeout(() => {
							try {
								addLog(`Video state: readyState=${video.readyState}, paused=${video.paused}, ended=${video.ended}`);

								ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
								addLog('Video frame successfully drawn!', false, true);

								// Start continuous rendering
								let frameCount = 0;
								function render() {
									ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
									if (frameCount < 3) {
										addLog(`Frame ${frameCount} rendered`);
										frameCount++;
									}
									requestAnimationFrame(render);
								}
								render();
								addLog('Started continuous rendering loop', false, true);

							} catch (e) {
								addLog(`ERROR drawing video: ${e.message}`, true);
							}
						}, 500);

					}, 500);
				});

				video.addEventListener('error', (e) => {
					addLog(`Video error: ${e.message}`, true);
				});

			} catch (err) {
				addLog(`ERROR: ${err.message}`, true);
			}
		}

		init();
	</script>
</body>
</html>
